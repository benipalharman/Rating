{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/b0201655/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Packages Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Text Preprocessing\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('stopwords') #Downloading stopWords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "\n",
    "#ignore the warnings from sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. IMPORTING THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/b0201655/Downloads/archive/kindle_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 982619 entries, 0 to 982618\n",
      "Data columns (total 10 columns):\n",
      "Unnamed: 0        982619 non-null int64\n",
      "asin              982619 non-null object\n",
      "helpful           982619 non-null object\n",
      "overall           982619 non-null int64\n",
      "reviewText        982597 non-null object\n",
      "reviewTime        982619 non-null object\n",
      "reviewerID        982619 non-null object\n",
      "reviewerName      978803 non-null object\n",
      "summary           982618 non-null object\n",
      "unixReviewTime    982619 non-null int64\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 75.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n",
       "      <td>05 5, 2014</td>\n",
       "      <td>A1F6404F1VG29J</td>\n",
       "      <td>Avidreader</td>\n",
       "      <td>Nice vintage story</td>\n",
       "      <td>1399248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>This book is a reissue of an old one; the auth...</td>\n",
       "      <td>01 6, 2014</td>\n",
       "      <td>AN0N05A9LIJEQ</td>\n",
       "      <td>critters</td>\n",
       "      <td>Different...</td>\n",
       "      <td>1388966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>This was a fairly interesting read.  It had ol...</td>\n",
       "      <td>04 4, 2014</td>\n",
       "      <td>A795DMNCJILA6</td>\n",
       "      <td>dot</td>\n",
       "      <td>Oldie</td>\n",
       "      <td>1396569600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>I'd never read any of the Amy Brewster mysteri...</td>\n",
       "      <td>02 19, 2014</td>\n",
       "      <td>A1FV0SX13TWVXQ</td>\n",
       "      <td>Elaine H. Turley \"Montana Songbird\"</td>\n",
       "      <td>I really liked it.</td>\n",
       "      <td>1392768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>If you like period pieces - clothing, lingo, y...</td>\n",
       "      <td>03 19, 2014</td>\n",
       "      <td>A3SPTOKDG7WBLN</td>\n",
       "      <td>Father Dowling Fan</td>\n",
       "      <td>Period Mystery</td>\n",
       "      <td>1395187200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin helpful  overall  \\\n",
       "0           0  B000F83SZQ  [0, 0]        5   \n",
       "1           1  B000F83SZQ  [2, 2]        4   \n",
       "2           2  B000F83SZQ  [2, 2]        4   \n",
       "3           3  B000F83SZQ  [1, 1]        5   \n",
       "4           4  B000F83SZQ  [0, 1]        4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  I enjoy vintage books and movies so I enjoyed ...   05 5, 2014   \n",
       "1  This book is a reissue of an old one; the auth...   01 6, 2014   \n",
       "2  This was a fairly interesting read.  It had ol...   04 4, 2014   \n",
       "3  I'd never read any of the Amy Brewster mysteri...  02 19, 2014   \n",
       "4  If you like period pieces - clothing, lingo, y...  03 19, 2014   \n",
       "\n",
       "       reviewerID                         reviewerName             summary  \\\n",
       "0  A1F6404F1VG29J                           Avidreader  Nice vintage story   \n",
       "1   AN0N05A9LIJEQ                             critters        Different...   \n",
       "2   A795DMNCJILA6                                  dot               Oldie   \n",
       "3  A1FV0SX13TWVXQ  Elaine H. Turley \"Montana Songbird\"  I really liked it.   \n",
       "4  A3SPTOKDG7WBLN                   Father Dowling Fan      Period Mystery   \n",
       "\n",
       "   unixReviewTime  \n",
       "0      1399248000  \n",
       "1      1388966400  \n",
       "2      1396569600  \n",
       "3      1392768000  \n",
       "4      1395187200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>A1F6404F1VG29J</td>\n",
       "      <td>Avidreader</td>\n",
       "      <td>Nice vintage story</td>\n",
       "      <td>1399248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>This book is a reissue of an old one; the auth...</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>AN0N05A9LIJEQ</td>\n",
       "      <td>critters</td>\n",
       "      <td>Different...</td>\n",
       "      <td>1388966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>This was a fairly interesting read.  It had ol...</td>\n",
       "      <td>2014-04-04</td>\n",
       "      <td>A795DMNCJILA6</td>\n",
       "      <td>dot</td>\n",
       "      <td>Oldie</td>\n",
       "      <td>1396569600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>I'd never read any of the Amy Brewster mysteri...</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>A1FV0SX13TWVXQ</td>\n",
       "      <td>Elaine H. Turley \"Montana Songbird\"</td>\n",
       "      <td>I really liked it.</td>\n",
       "      <td>1392768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>If you like period pieces - clothing, lingo, y...</td>\n",
       "      <td>2014-03-19</td>\n",
       "      <td>A3SPTOKDG7WBLN</td>\n",
       "      <td>Father Dowling Fan</td>\n",
       "      <td>Period Mystery</td>\n",
       "      <td>1395187200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  B000F83SZQ  [0, 0]        5   \n",
       "1  B000F83SZQ  [2, 2]        4   \n",
       "2  B000F83SZQ  [2, 2]        4   \n",
       "3  B000F83SZQ  [1, 1]        5   \n",
       "4  B000F83SZQ  [0, 1]        4   \n",
       "\n",
       "                                          reviewText reviewTime  \\\n",
       "0  I enjoy vintage books and movies so I enjoyed ... 2014-05-05   \n",
       "1  This book is a reissue of an old one; the auth... 2014-01-06   \n",
       "2  This was a fairly interesting read.  It had ol... 2014-04-04   \n",
       "3  I'd never read any of the Amy Brewster mysteri... 2014-02-19   \n",
       "4  If you like period pieces - clothing, lingo, y... 2014-03-19   \n",
       "\n",
       "       reviewerID                         reviewerName             summary  \\\n",
       "0  A1F6404F1VG29J                           Avidreader  Nice vintage story   \n",
       "1   AN0N05A9LIJEQ                             critters        Different...   \n",
       "2   A795DMNCJILA6                                  dot               Oldie   \n",
       "3  A1FV0SX13TWVXQ  Elaine H. Turley \"Montana Songbird\"  I really liked it.   \n",
       "4  A3SPTOKDG7WBLN                   Father Dowling Fan      Period Mystery   \n",
       "\n",
       "   unixReviewTime  \n",
       "0      1399248000  \n",
       "1      1388966400  \n",
       "2      1396569600  \n",
       "3      1392768000  \n",
       "4      1395187200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "#drop the rows where there are no reviews\n",
    "df.dropna(subset = ['reviewText'], inplace = True)\n",
    "\n",
    "#changing the reviewTime column to be of datetime type\n",
    "df.reviewTime = pd.to_datetime(df.reviewTime)\n",
    "\n",
    "#creating a column with just the year\n",
    "# df['Year'] = df.reviewTime.dt.year\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>This book is a reissue of an old one; the auth...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>This was a fairly interesting read.  It had ol...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I'd never read any of the Amy Brewster mysteri...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>If you like period pieces - clothing, lingo, y...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  I enjoy vintage books and movies so I enjoyed ...        5\n",
       "1  This book is a reissue of an old one; the auth...        4\n",
       "2  This was a fairly interesting read.  It had ol...        4\n",
       "3  I'd never read any of the Amy Brewster mysteri...        5\n",
       "4  If you like period pieces - clothing, lingo, y...        4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = df[['reviewText', 'overall']]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Remove punctuations, special characters and stopwords from the text column. Convert the text to lower case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Data :This book is a reissue of an old one; the author was born in 1910. It's of the era of, say, Nero Wolfe. The introduction was quite interesting, explaining who the author was and why he's been forgotten; I'd never heard of him.The language is a little dated at times, like calling a gun a &#34;heater.&#34;  I also made good use of my Fire's dictionary to look up words like &#34;deshabille&#34; and &#34;Canarsie.&#34; Still, it was well worth a look-see.\n",
      "\n",
      "\n",
      "Data after removing punctuations: This book is a reissue of an old one the author was born in 1910 Its of the era of say Nero Wolfe The introduction was quite interesting explaining who the author was and why hes been forgotten Id never heard of himThe language is a little dated at times like calling a gun a 34heater34 I also made good use of my Fires dictionary to look up words like 34deshabille34 and 34Canarsie34 Still it was well worth a looksee\n",
      "\n",
      "\n",
      "Data after removing special Characters: This book is a reissue of an old one the author was born in Its of the era of say Nero Wolfe The introduction was quite interesting explaining who the author was and why hes been forgotten Id never heard of himThe language is a little dated at times like calling a gun a I also made good use of my Fires dictionary to look up words like and Still it was well worth a looksee\n",
      "\n",
      "\n",
      "Data after removing Stopwords: This book reissue old one author born Its era say Nero Wolfe The introduction quite interesting explaining author hes forgotten Id never heard himThe language little dated times like calling gun I also made good use Fires dictionary look words like Still well worth looksee\n",
      "\n",
      "\n",
      "Data after converting to lowercase : this book reissue old one author born its era say nero wolfe the introduction quite interesting explaining author hes forgotten id never heard himthe language little dated times like calling gun i also made good use fires dictionary look words like still well worth looksee\n"
     ]
    }
   ],
   "source": [
    "print('Actual Data :' + str(reviews['reviewText'][1]))\n",
    "print('\\n')\n",
    "\n",
    "#Removing punctuations\n",
    "punc = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "reviews['reviewText'] = reviews['reviewText'].apply(lambda x : ' '.join(word.translate(punc) for word in x.split()))\n",
    "print('Data after removing punctuations: ' + str(reviews['reviewText'][1]))\n",
    "print('\\n')\n",
    "\n",
    "#Removing non alpha character(Special Characters)\n",
    "reviews['reviewText'] = reviews['reviewText'].apply(lambda x: ' '.join(word for word in x.split() if word.isalpha()))\n",
    "print('Data after removing special Characters: '+ str(reviews['reviewText'][1]))\n",
    "print('\\n')\n",
    "\n",
    "#Lemmatize words to reduce them to their root form. Note: added the pos = 'v' to reduce the incoming word to verb root\n",
    "# nltk.download('wordnet')\n",
    "# lem = WordNetLemmatizer()\n",
    "# reviews['reviewText'] = reviews['reviewText'].apply(lambda x : ' '.join(lem.lemmatize(word, pos = 'v') for word in x.split()))\n",
    "# print('Lemmatized Text: ' + str(reviews['reviewText'][1]))\n",
    "# print('\\n')\n",
    "\n",
    "#Removing stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "reviews['reviewText'] = reviews['reviewText'].apply(lambda x : ' '.join(word for word in x.split() if word not in stop))\n",
    "print('Data after removing Stopwords: ' + str(reviews['reviewText'][1]))\n",
    "print('\\n')\n",
    "\n",
    "#Converting the text to lower case. \n",
    "reviews['reviewText'] = reviews['reviewText'].apply(lambda x: ' '.join(word.lower() for word in x.split()))\n",
    "print('Data after converting to lowercase : '+ str(reviews['reviewText'][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Create two objects X and y. X will be the ' reviewText ' column dataframe and y will be the “Overall Rating” column. create a CountVectorizer object and split the data into training and testing sets. Train a MultinomialNB model and Display the confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balancing the training data by downsampling to the minority class given there is a good amount of data\n",
    "def make_xy(data, vec, n):\n",
    "    \n",
    "    temp = pd.DataFrame()\n",
    "    #sampling only n class reviews per class\n",
    "    for rating in range(2):\n",
    "        temp = pd.concat([temp, data[data.overall == rating].sample(n, random_state = 42)], ignore_index = True)\n",
    "    #vectorizing the vocabulary\n",
    "    X = vec.fit_transform(temp.reviewText)\n",
    "    y = temp.overall\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    925449\n",
       "0     57148\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separating the ratings to different sentiment \n",
    "r1 = reviews[reviews.overall.isin([3,4,5])]\n",
    "r0 = reviews[reviews.overall.isin([1,2])]\n",
    "r1.loc[:, 'overall'] = 1\n",
    "r0.loc[:, 'overall'] = 0\n",
    "\n",
    "#concat the two new dataframes return one dataframe with preprocessed text and their corresponding labels\n",
    "rev = pd.concat([r1,r0])\n",
    "rev.head()\n",
    "rev.overall.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using CountVectorizer\n",
    "count = CountVectorizer()\n",
    "X, y = make_xy(rev, count, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy w/ CountVectorizer: 0.92\n",
      "Testing Accuracy w/ CountVectorizer: 0.88\n"
     ]
    }
   ],
   "source": [
    "#testing the model with CountVectorizer\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 42, stratify = y)\n",
    "\n",
    "naive = MultinomialNB()\n",
    "naive.fit(X_train, y_train)\n",
    "print('Training Accuracy w/ CountVectorizer: {:.2f}'.format(naive.score(X_train, y_train)))\n",
    "print('Testing Accuracy w/ CountVectorizer: {:.2f}'.format(naive.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5510  490]\n",
      " [ 956 5044]]\n"
     ]
    }
   ],
   "source": [
    "nb_pred=naive.predict(X_test)\n",
    "print(confusion_matrix(y_test, nb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Display the POS tagging on the first 4 rows of ‘reviewText’ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/b0201655/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/b0201655/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Text::this book reissue old one author born its era say nero wolfe the introduction quite interesting explaining author hes forgotten id never heard himthe language little dated times like calling gun i also made good use fires dictionary look words like still well worth looksee\n",
      "POS Tagging::[('book', 'NN'), ('reissue', 'NN'), ('old', 'JJ'), ('one', 'CD'), ('author', 'NN'), ('born', 'VBN'), ('era', 'NNS'), ('say', 'VBP'), ('nero', 'JJ'), ('wolfe', 'JJ'), ('introduction', 'NN'), ('quite', 'RB'), ('interesting', 'JJ'), ('explaining', 'VBG'), ('author', 'NN'), ('hes', 'NNS'), ('forgotten', 'VBP'), ('id', 'JJ'), ('never', 'RB'), ('heard', 'VBP'), ('himthe', 'JJ'), ('language', 'NN'), ('little', 'RB'), ('dated', 'JJ'), ('times', 'NNS'), ('like', 'IN'), ('calling', 'VBG'), ('gun', 'NN'), ('also', 'RB'), ('made', 'VBD'), ('good', 'JJ'), ('use', 'NN'), ('fires', 'NNS'), ('dictionary', 'JJ'), ('look', 'VBP'), ('words', 'NNS'), ('like', 'IN'), ('still', 'RB'), ('well', 'RB'), ('worth', 'JJ'), ('looksee', 'NN')]\n",
      "\n",
      "\n",
      "Review Text::this fairly interesting read it old style terminologyi glad get read story doesnt coarse crasslanguage i read fun relaxationi like free ebooksbecause i check writer decide intriguinginnovative enough command englishthat convey story without crude language\n",
      "POS Tagging::[('fairly', 'RB'), ('interesting', 'JJ'), ('read', 'JJ'), ('old', 'JJ'), ('style', 'NN'), ('terminologyi', 'NN'), ('glad', 'JJ'), ('get', 'NN'), ('read', 'JJ'), ('story', 'NN'), ('doesnt', 'JJ'), ('coarse', 'JJ'), ('crasslanguage', 'NN'), ('read', 'VBD'), ('fun', 'JJ'), ('relaxationi', 'NNS'), ('like', 'IN'), ('free', 'JJ'), ('ebooksbecause', 'NN'), ('check', 'NN'), ('writer', 'NN'), ('decide', 'VBP'), ('intriguinginnovative', 'JJ'), ('enough', 'RB'), ('command', 'NN'), ('englishthat', 'WP'), ('convey', 'VBZ'), ('story', 'NN'), ('without', 'IN'), ('crude', 'NN'), ('language', 'NN')]\n",
      "\n",
      "\n",
      "Review Text::id never read amy brewster mysteries one so i really hooked\n",
      "POS Tagging::[('id', 'NN'), ('never', 'RB'), ('read', 'VBD'), ('amy', 'JJ'), ('brewster', 'NN'), ('mysteries', 'NNS'), ('one', 'CD'), ('really', 'RB'), ('hooked', 'JJ')]\n",
      "\n",
      "\n",
      "Review Text::if like period pieces clothing lingo enjoy mystery author guessing least way\n",
      "POS Tagging::[('like', 'IN'), ('period', 'NN'), ('pieces', 'NNS'), ('clothing', 'VBG'), ('lingo', 'JJ'), ('enjoy', 'JJ'), ('mystery', 'NN'), ('author', 'NN'), ('guessing', 'VBG'), ('least', 'JJS'), ('way', 'NN')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "for x in range(1, 5):\n",
    "    reviewText=str(reviews['reviewText'][x])\n",
    "    tokenized = sent_tokenize(reviewText) \n",
    "    for i in tokenized: \n",
    "      \n",
    "        # Word tokenizers is used to find the words  \n",
    "        # and punctuation in a string \n",
    "        wordsList = nltk.word_tokenize(i) \n",
    "  \n",
    "        # removing stop words from wordList \n",
    "        wordsList = [w for w in wordsList if not w in stop_words]  \n",
    "  \n",
    "        #  Using a Tagger. Which is part-of-speech  \n",
    "        # tagger or POS-tagger.  \n",
    "        tagged = nltk.pos_tag(wordsList) \n",
    "  \n",
    "        print('Review Text::'+ reviewText ) \n",
    "        \n",
    "        print('POS Tagging::'+ str(tagged))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Build and display a dependency parser tree for the sentence\n",
    "\n",
    "“When Jon Snow is stranded north of the Wall, half-frozen and under attack by wights, Benjen rides in and puts Jon on his horse.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        rides                                                     \n",
      "   _______________________|______________________________________________          \n",
      "  |     |   |                 stranded                                   |        \n",
      "  |     |   |    ________________|_______                                |         \n",
      "  |     |   |   |    |    |            north                             |        \n",
      "  |     |   |   |    |    |              |                               |         \n",
      "  |     |   |   |    |    |              of                              |        \n",
      "  |     |   |   |    |    |       _______|_____________________          |         \n",
      "  |     |   |   |    |    |      |               |           under      puts      \n",
      "  |     |   |   |    |    |      |               |             |      ___|_____    \n",
      "  |     |   |   |    |    |      |               |           attack  |         on \n",
      "  |     |   |   |    |    |      |               |             |     |         |   \n",
      "  |     |   |   |    |   Snow    |           halffrozen        by    |       horse\n",
      "  |     |   |   |    |    |      |        _______|_______      |     |         |   \n",
      "Benjen  in and When  is  Jon    and     the             Wall wights Jon       his \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(txt):\n",
    "  txt_removepunct= \"\".join([ a for a in txt if a not in string.punctuation])\n",
    "  return txt_removepunct\n",
    "\n",
    "import spacy\n",
    "from nltk import Tree\n",
    "\n",
    "loadspacy = spacy.load('en')\n",
    "\n",
    "st=\"When Jon Snow is stranded north of the Wall, half-frozen and under attack by wights, Benjen rides in and puts Jon on his horse.\"\n",
    "\n",
    "spacydoc = loadspacy(remove_punctuation(st))\n",
    "\n",
    "def dependencyParseTree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_, [dependencyParseTree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_\n",
    "\n",
    "[dependencyParseTree(sent.root).pretty_print() for sent in spacydoc.sents]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
